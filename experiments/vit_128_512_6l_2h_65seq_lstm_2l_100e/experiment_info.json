{
    "best_epoch": {
        "number": 15,
        "train_loss": 4.315873979013177,
        "eval_loss": 4.30548
    },
    "history": {
        "train": [
            8.609323483479175,
            4.614390095577964,
            4.606606320489811,
            4.591026070751721,
            4.529715326767933,
            4.4717580879790875,
            4.4315538828886005,
            4.406640650350837,
            4.3905764833281316,
            4.3798571115807645,
            4.371822326998167,
            4.361318624472316,
            4.351292091079905,
            4.338045560860936,
            4.325946005084846,
            4.315873979013177
        ],
        "eval": [
            4.62723,
            4.61905,
            4.60848,
            4.57788,
            4.49137,
            4.44938,
            4.42367,
            4.39967,
            4.38686,
            4.38563,
            4.36487,
            4.35798,
            4.34628,
            4.33005,
            4.32966,
            4.30548
        ]
    },
    "architecture": "OCR_ViTRNN(\n  (batch_norm): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (encoder): ViTModel(\n    (embeddings): ViTEmbeddings(\n      (patch_embeddings): ViTPatchEmbeddings(\n        (projection): Conv2d(3, 128, kernel_size=(32, 32), stride=(32, 32))\n      )\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): ViTEncoder(\n      (layer): ModuleList(\n        (0): ViTLayer(\n          (attention): ViTAttention(\n            (attention): ViTSelfAttention(\n              (query): Linear(in_features=128, out_features=128, bias=False)\n              (key): Linear(in_features=128, out_features=128, bias=False)\n              (value): Linear(in_features=128, out_features=128, bias=False)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n            (output): ViTSelfOutput(\n              (dense): Linear(in_features=128, out_features=128, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ViTIntermediate(\n            (dense): Linear(in_features=128, out_features=512, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): ViTOutput(\n            (dense): Linear(in_features=512, out_features=128, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (layernorm_before): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n          (layernorm_after): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n        )\n        (1): ViTLayer(\n          (attention): ViTAttention(\n            (attention): ViTSelfAttention(\n              (query): Linear(in_features=128, out_features=128, bias=False)\n              (key): Linear(in_features=128, out_features=128, bias=False)\n              (value): Linear(in_features=128, out_features=128, bias=False)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n            (output): ViTSelfOutput(\n              (dense): Linear(in_features=128, out_features=128, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ViTIntermediate(\n            (dense): Linear(in_features=128, out_features=512, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): ViTOutput(\n            (dense): Linear(in_features=512, out_features=128, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (layernorm_before): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n          (layernorm_after): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n        )\n        (2): ViTLayer(\n          (attention): ViTAttention(\n            (attention): ViTSelfAttention(\n              (query): Linear(in_features=128, out_features=128, bias=False)\n              (key): Linear(in_features=128, out_features=128, bias=False)\n              (value): Linear(in_features=128, out_features=128, bias=False)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n            (output): ViTSelfOutput(\n              (dense): Linear(in_features=128, out_features=128, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ViTIntermediate(\n            (dense): Linear(in_features=128, out_features=512, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): ViTOutput(\n            (dense): Linear(in_features=512, out_features=128, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (layernorm_before): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n          (layernorm_after): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n        )\n        (3): ViTLayer(\n          (attention): ViTAttention(\n            (attention): ViTSelfAttention(\n              (query): Linear(in_features=128, out_features=128, bias=False)\n              (key): Linear(in_features=128, out_features=128, bias=False)\n              (value): Linear(in_features=128, out_features=128, bias=False)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n            (output): ViTSelfOutput(\n              (dense): Linear(in_features=128, out_features=128, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ViTIntermediate(\n            (dense): Linear(in_features=128, out_features=512, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): ViTOutput(\n            (dense): Linear(in_features=512, out_features=128, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (layernorm_before): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n          (layernorm_after): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n        )\n        (4): ViTLayer(\n          (attention): ViTAttention(\n            (attention): ViTSelfAttention(\n              (query): Linear(in_features=128, out_features=128, bias=False)\n              (key): Linear(in_features=128, out_features=128, bias=False)\n              (value): Linear(in_features=128, out_features=128, bias=False)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n            (output): ViTSelfOutput(\n              (dense): Linear(in_features=128, out_features=128, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ViTIntermediate(\n            (dense): Linear(in_features=128, out_features=512, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): ViTOutput(\n            (dense): Linear(in_features=512, out_features=128, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (layernorm_before): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n          (layernorm_after): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n        )\n        (5): ViTLayer(\n          (attention): ViTAttention(\n            (attention): ViTSelfAttention(\n              (query): Linear(in_features=128, out_features=128, bias=False)\n              (key): Linear(in_features=128, out_features=128, bias=False)\n              (value): Linear(in_features=128, out_features=128, bias=False)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n            (output): ViTSelfOutput(\n              (dense): Linear(in_features=128, out_features=128, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ViTIntermediate(\n            (dense): Linear(in_features=128, out_features=512, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): ViTOutput(\n            (dense): Linear(in_features=512, out_features=128, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (layernorm_before): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n          (layernorm_after): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n        )\n      )\n    )\n    (layernorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n  )\n  (decoder): BiLSTMImageDecoder(\n    (norm): BatchNorm1d(65, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (rnn): LSTM(128, 128, num_layers=2, dropout=0.1, bidirectional=True)\n    (out_proj): Linear(in_features=256, out_features=65, bias=True)\n  )\n  (softmax): LogSoftmax(dim=-1)\n)"
}